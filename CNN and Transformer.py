# -*- coding: utf-8 -*-
"""CS189 HW6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PNQh5Dme4yi2nxH879wWjPrvPSouqRat

# Problem 2: MNIST: Hand-written digit classification
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms

"""## Loading MNIST
The `torchvision` module contains links to many standard datasets. We can load the MNIST dataset into a `Dataset` object as follows:
"""

train_dataset = datasets.MNIST('./data', train=True, download=True,  # Downloads into a directory ../data
                               transform=transforms.ToTensor())
train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, 
                                                             [int(len(train_dataset)*0.8), int(len(train_dataset)*0.2)], 
                                                             generator=torch.Generator().manual_seed(42))
test_dataset = datasets.MNIST('./data', train=False, download=False,  # No need to download again
                              transform=transforms.ToTensor())

"""The `Dataset` object is an iterable where each element is a tuple of (input `Tensor`, target):"""

print(train_dataset[0][0])

type(train_dataset[0][1])

"""2a) Structure of the dataset"""

print(train_dataset[0][0][0].shape)

print(28*28)

"""The height and width of the images are 28 by 28. There is one channel per image. The values in the first array index represent the sample point as a tuple. The second index represent the tensor including the training data, the third value in the index represent the actual training data"""

print(len(train_dataset))

print(len(valid_dataset))

"""There are 48000 images in the training set, 12000 images in the testing set.

We can convert images to numpy arrays and plot them with matplotlib:
"""

plt.imshow(train_dataset[0][0][0].numpy(), cmap='gray')

"""## Example linear model
Let's instantiate a linear model and take a look at the layers.
"""

model = nn.Sequential(
    # For fully-connected networks, we don't use the 2D structure of an image at all. Our network
    # takes in a flat vector of the pixel values as input.
    nn.Flatten(),  
    nn.Linear(784, 10),
)
print(model)

"""## Training and validation

Now let's try to train the linear model as an example.
"""

def run_training_loop(model, batch_size=32, n_epochs=10, lr=1e-3):

    # We could write our training procedure manually and directly index the `Dataset` objects,
    # but the `DataLoader` object conveniently creates an iterable for automatically creating random minibatches:
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)

    # Choose Adam as the optimizer
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    # Use the cross entropy loss function
    loss_fn = nn.CrossEntropyLoss()

    # store metrics
    train_loss_history = np.zeros([n_epochs, 1])
    valid_accuracy_history = np.zeros([n_epochs, 1])
    valid_loss_history = np.zeros([n_epochs, 1])

    for epoch in range(n_epochs):

        # Some layers, such as Dropout, behave differently during training
        model.train()

        train_loss = 0
        for batch_idx, (data, target) in enumerate(train_loader):

            # Erase accumulated gradients
            optimizer.zero_grad()

            # Forward pass
            output = model(data)

            # Calculate loss
            loss = loss_fn(output, target)
            train_loss += loss.item()

            # Backward pass
            loss.backward()
            
            # Weight update
            optimizer.step()

        train_loss_history[epoch] = train_loss / len(train_loader.dataset)

        # Track loss each epoch
        print('Train Epoch: %d  Average loss: %.4f' %
              (epoch + 1,  train_loss_history[epoch]))

        # Putting layers like Dropout into evaluation mode
        model.eval()

        valid_loss = 0
        correct = 0

        # Turning off automatic differentiation
        with torch.no_grad():
            for data, target in valid_loader:
                output = model(data)
                valid_loss += loss_fn(output, target).item()  # Sum up batch loss
                pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score
                correct += pred.eq(target.view_as(pred)).sum().item()

        valid_loss_history[epoch] = valid_loss / len(valid_loader.dataset)
        valid_accuracy_history[epoch] = correct / len(valid_loader.dataset)

        print('Valid set: Average loss: %.4f, Accuracy: %d/%d (%.4f)\n' %
              (valid_loss_history[epoch], correct, len(valid_loader.dataset),
              100. * valid_accuracy_history[epoch]))
    
    return model, train_loss_history, valid_loss_history, valid_accuracy_history

trained_model, train_loss_history, valid_loss_history, valid_accuracy_history = run_training_loop(model)
plt.plot(train_loss_history, label='train')
plt.plot(valid_loss_history, label='valid')
plt.legend()
plt.show()

"""## Testing
After selecting hyperparameters from the validation set, evaluate on the held-out test set (distinct from the validation set).
"""

def test_performance(model, batch_size=32):
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True) 

    # Putting layers like Dropout into evaluation mode
    model.eval()
    # Use the cross entropy loss function
    loss_fn = nn.CrossEntropyLoss()

    test_loss = 0
    correct = 0

    # Turning off automatic differentiation
    with torch.no_grad():
        for data, target in test_loader:
            output = model(data)
            test_loss += loss_fn(output, target).item()  # Sum up batch loss
            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)
    test_accuracy = correct / len(test_loader.dataset)

    print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %
          (test_loss, correct, len(test_loader.dataset),
          100. * test_accuracy))
    return test_loss, test_accuracy

test_performance(model)

"""Not bad! Even the linear model gets above 92% accuracy.

## Visualizing predictions

We can visualize and inspect the model predictions. Here is an example of how to visualize the wrongly classified cases among the first 20 validation examples.
"""

# Putting layers like Dropout into evaluation mode
model.eval()

# Turning off automatic differentiation
with torch.no_grad():
      for i in range(20):
        data, target = valid_dataset[i]
        output = model(data)
        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score
        if pred.item() != target:
            plt.imshow(data[0].numpy(), cmap='gray')
            plt.title(f'Predicted: {pred.item()}')
            plt.show()

"""# Your code: 2 (b)"""

model = nn.Sequential(
    # In problem 2, we don't use the 2D structure of an image at all. Our network
    # takes in a flat vector of the pixel values as input.
    nn.Flatten(),  
    nn.Linear(784,100),
    nn.ReLU(),
    nn.Linear(100,100),
    nn.ReLU(),
    nn.Linear(100,10),
    # TODO
)

trained_model, train_loss_history, valid_loss_history, valid_accuracy_history = run_training_loop(model)
plt.plot(train_loss_history, label='train')
plt.plot(valid_loss_history, label='valid')
plt.legend()
plt.show()

test_performance(model)

"""I implemented a feedforward model with 2 hidden layers each with 100 units and each with bias. With ReLU activation for hidden layers and no softmax activation for the final layer. No regularization is used as there is no overfitting.

# Example code for convolutional neural networks
"""

# sample model
import torch.nn as nn

model = nn.Sequential(
    nn.Conv2d(1, 8, kernel_size=(8,8)),
    nn.ReLU(),
    nn.MaxPool2d(8),
    nn.Dropout(p=0.5),
    
    nn.Flatten(),
    nn.Linear(32, 64),
    nn.ReLU(),
    nn.Linear(64, 10)
    # PyTorch implementation of cross-entropy loss includes softmax layer
)

# take a look at the shape of the weights for each layer
for p in model.parameters():
    print(p.data.shape)


# our model has some # of parameters:
count = 0
for p in model.parameters():
    n_params = np.prod(list(p.data.shape)).item()
    count += n_params
print(f'total params: {count}')

trained_model, train_loss_history, valid_loss_history, valid_accuracy_history = run_training_loop(model)
plt.plot(train_loss_history, label='train')
plt.plot(valid_loss_history, label='valid')
plt.legend()
plt.show()

test_performance(model)

"""## Your code: 2 (c)"""

from torch.nn.modules.activation import Softmax
from torch.nn.modules.flatten import Flatten
from torch.nn.modules.batchnorm import BatchNorm2d
model = nn.Sequential(
    # TODO
    nn.Conv2d(1,32, kernel_size = (6,6), stride = 2, padding=(3,3)),
    nn.BatchNorm2d(32),
    nn.ReLU(),
    nn.MaxPool2d(kernel_size = 2, padding=(1,0)),

    nn.Conv2d(32,44, kernel_size = (5,5)),
    nn.BatchNorm2d(44),
    nn.ReLU(),
    nn.MaxPool2d(kernel_size = 2),

    nn.Flatten(),
    nn.Linear(88, 64),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(64, 10),
    # nn.Softmax()
)

# make sure the # of parameters is under 50,000
count = 0
for p in model.parameters():
    n_params = np.prod(list(p.data.shape)).item()
    count += n_params
print(f'total params: {count}')

trained_model, train_loss_history, valid_loss_history, valid_accuracy_history = run_training_loop(model)
plt.plot(train_loss_history, label='train')
plt.plot(valid_loss_history, label='valid')
plt.legend()
plt.show()

test_performance(model)

"""I used 2 convolution layers with strides and max pooling to increase the receptive fields of the final output. I also applied batch norm to regularize the convolution output to make model less sensitive to higher learning rates and initialization. I then implemented a feedforward neural network with one hidden layer and used dropout in the last step as regularization before I get to the final output layer. I tried the model with and without batch normalization and found out that batch normalization significantly improved the accuracy. I also tried adding and deleting softmax as the activation function for the output and I found that deleting softmax gives a better result.

# Problem 3: Vision Transformer
"""

!pip install einops

import torch
from torch import nn

from einops import rearrange, repeat
from einops.layers.torch import Rearrange

"""## Your code: 3(a)

Implement single-head attention.
"""

class SingleHeadAttention(nn.Module):
    def __init__(self, input_dim, inner_dim, dropout = 0.):
        super().__init__()
        # TODO
        self.q = nn.Linear(input_dim, inner_dim)
        self.k = nn.Linear(input_dim, inner_dim)
        self.v = nn.Linear(input_dim, inner_dim)
        self.dropout = nn.Dropout(p=dropout)
        self.softmax = nn.Softmax(dim=-1)
        self.d_k = inner_dim

    def forward(self, x):
        # TODO
        Q = self.q(x)
        K = self.k(x)
        V = self.v(x)

        attn_weights = self.softmax(torch.matmul(Q, torch.transpose(K, -2, -1)) / np.sqrt(self.d_k))
        out = torch.matmul(attn_weights, V)
        
        out = self.dropout(out)

        return out, attn_weights

# model.transformer[5].attn[1].attention_heads[0].attentionmatrix

"""Test the following multihead attention implementation that relies on the single-head attention implementation above."""

class Attention(nn.Module):
    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):
        super().__init__()
        self.attention_heads = nn.ModuleList([
            SingleHeadAttention(dim, dim_head, dropout=dropout)
            for _ in range(heads)
        ])

    def forward(self, x):
        outputs = [head(x) for head in self.attention_heads]
        out = torch.cat([output[0] for output in outputs], dim=-1)
        attn_matrix = torch.stack([output[1] for output in outputs])
        return out, attn_matrix

"""Test code for multihead attention:"""

T = 5
input_dim = 32
batch_size = 20

heads = 8
dim_head = 64

test_input = torch.zeros((batch_size, T, input_dim))

test_attention_module = Attention(input_dim)
test_output, test_attn_matrix = test_attention_module(test_input)

print(test_output)
assert test_output.size() == (batch_size, T, heads * dim_head), "Shapes are incorrect"

"""## Your code: 3 (b)"""

class ViTLayer(nn.Module):
    def __init__(self, dim, heads, dim_head, mlp_dim, dropout = 0.):
        super().__init__()
        self.attn = nn.Sequential(
            # TODO
            nn.LayerNorm(dim),
            Attention(dim=dim,heads=heads, dim_head=dim_head, dropout=dropout),
        )
        self.feedforward = nn.Sequential(
            # TODO
            nn.LayerNorm(dim),
            #A
            nn.Linear(dim,mlp_dim),
            nn.Dropout(p=dropout),
            #Relu
            nn.ReLU(),
            #B
            nn.Linear(mlp_dim,dim),
            #dropout
            nn.Dropout(p=dropout)
        )
        self.attn_project = nn.Linear(heads*dim_head,dim)

    def forward(self, x):
        # TODO
        outattn, attn_matrix = self.attn(x)
        outattn = self.attn_project(outattn) + x
        #apply feedforward
        outmlp = self.feedforward(outattn)
        out = outattn + outmlp
        return out, attn_matrix

"""## ViT code for 3 (c)"""

class ViT(nn.Module):
    def __init__(self, patch_size=7, dim=64, depth=6, heads=8, mlp_dim=128, 
                 dim_head = 64,
                 dropout = 0., emb_dropout = 0.):
        super().__init__()

        image_height, image_width = 28, 28
        num_classes = 10
        channels = 1

        patch_height = patch_size
        patch_width = patch_size

        assert image_height % patch_height == 0 and image_width % patch_width == 0, (
            'Image dimensions must be divisible by the patch size.')

        num_patches = (image_height // patch_height) * (image_width // patch_width)
        patch_dim = channels * patch_height * patch_width

        self.to_patch_embedding = nn.Sequential(
            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),
            nn.Linear(patch_dim, dim),
        )

        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))
        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))
        self.emb_dropout = nn.Dropout(emb_dropout)

        self.transformer = nn.Sequential(*nn.ModuleList([
            ViTLayer(dim, heads, dim_head, mlp_dim, dropout)
            for _ in range(depth)                       
        ]))

        self.mlp_head = nn.Sequential(
            nn.LayerNorm(dim),
            nn.Linear(dim, num_classes)
        )

    def forward(self, img, return_attn_matrix = False):
        x = self.to_patch_embedding(img)
        b, n, _ = x.shape

        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)
        x = torch.cat((cls_tokens, x), dim=1)
        x += self.pos_embedding[:, :(n + 1)]
        x = self.emb_dropout(x)
        for layer in self.transformer:
          x, attn_matrix = layer(x)

        x = x[:, 0]
        if return_attn_matrix:
          return self.mlp_head(x), attn_matrix
        else:
          return self.mlp_head(x)

model = ViT(patch_size=7, dim=64, depth=6, heads=8, mlp_dim=128)

trained_model, train_loss_history, valid_loss_history, valid_accuracy_history = run_training_loop(model)
plt.plot(train_loss_history, label='train')
plt.plot(valid_loss_history, label='valid')
plt.legend()
plt.show()

test_performance(model)

valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)
with torch.no_grad():
  for data, target in valid_loader:
      output, attn_matrix = trained_model(data, return_attn_matrix = True)
      break

matrix = []
for i in attn_matrix:
  i = torch.mean(i,0)
  matrix.append(i)
  
fig, ax = plt.subplots(2, 4, figsize=(14,14))
for i in np.arange(2):
    for j in np.arange(4):
        ax[i,j].imshow(matrix[j+4*i],cmap = "hot")
fig.suptitle("validation attention weights for 8 heads")

